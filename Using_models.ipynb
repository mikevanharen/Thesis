{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Using_models.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "r5MWnroNJCTg",
        "fmhrH6NaK3G0",
        "fH0YD6E_Vt7X",
        "S-4OIxj0XHjV",
        "_Tww8cXcJaBc",
        "37x1ipprxpET",
        "jWEoHSuzL4fy",
        "WUc8ViYcOZ4N",
        "F5tC_VY5NJBx"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6-final"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvksjtBgJDxm"
      },
      "source": [
        "# Pipeline\n",
        "After importing the necessary functions we load the data from 'movie_labels.csv' to get all the movies and labels for every genre. Also, we get the amount of movies for every genre for visualisation at the end. \n",
        "\n",
        "Then, we create the use_model function and the preporatory things for creating the dataloaders. Also, we load in the trained classifiers (both single-image validation and profile validation).\n",
        "\n",
        "Now, we load the data from 'user_profiles.csv' to get the movies (and labels for these movies) for every profile. Afterwards, we create a dataloader with all the movies. This is because, for every genre, we want to make a single prediction for all movies and then use that single prediction for every profile with that movie. This is to make sure the only difference is in the profiles and not the classification of the same movie between different profiles.\n",
        "\n",
        "With this preporatory work, we can finally start getting the predictions for all the movies. These predictions are then loaded into the 'movie_dictionary.csv' file, which means we don't have to redo all this work multiple times. Assuming this worked, we can now load the results from 'movie_dictionary' into the variable 'old_movie_dictionary' and all the results from 'new_movie_dictionary' into the variable with the same name.\n",
        "\n",
        "With these predictions we can start testing to see the results. The testing is done using profiles instead of single images. So, we have to first take a test set of the profiles. This is done by taking the true labels of the profiles and then splitting them up in training, validation, and test sets. From which we only use the test set. Then, we get the true labels of the profiles in the test set, as well as the predicted labels of the profiles in the test set. These can be used to get the accuracies. These accuracies can then be visualised together with the (relative) amount of movies for every genre.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5MWnroNJCTg"
      },
      "source": [
        "# Imports and connecting to Google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Fs_YWt6XHjG"
      },
      "source": [
        "%matplotlib inline\n",
        "#ZL: plot within the notebook \n",
        "# for colab, choose runtime, select GPU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2X12e-yXHjN"
      },
      "source": [
        "# License: BSD\n",
        "# Author: Sasank Chilamkurthy\n",
        "# Zhuoran and me changed some things\n",
        "\n",
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "import csv\n",
        "import random\n",
        "import math\n",
        "\n",
        "from PIL import Image, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "plt.ion()   # interactive mode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udIXL8vFkQp1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDC73SpwlaAn"
      },
      "source": [
        "!unzip 'drive/MyDrive/movies_data_split.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY4M34LypfQy"
      },
      "source": [
        "def updateDict(dictionary, genre, element):\n",
        "  dict_list = dictionary.get(genre, [])\n",
        "  dict_list.append(element)\n",
        "\n",
        "  return dict_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmhrH6NaK3G0"
      },
      "source": [
        "# Get all the movies and make lists per genre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u36VKSn17E5w"
      },
      "source": [
        "genre_dict = {'Action':0, 'Adventure':1, 'Animation_Children\\'s':2, 'Comedy':3, 'Crime':4, \n",
        "              'Documentary':5, 'Drama':6, 'Fantasy_Sci-Fi':7, 'Film-Noir':8, 'Horror_Thriller':9, \n",
        "              'Musical':10, 'Mystery':11, 'Romance':12, 'War':13, 'Western':14}\n",
        "row_names = ['movie_id', 'genre_array']\n",
        "count = {}\n",
        "\n",
        "# Separate list for all movies, movies that have the genre, and those that don't. Finally, the movies used for testing\n",
        "all_movies = {}\n",
        "movies = {}\n",
        "non_movies = {}\n",
        "\n",
        "# Dictionary for every movie, for every genre. To be used later, in loading the user's movies.\n",
        "movie_labels = {} # movie_labels[movie][genre]\n",
        "\n",
        "# Keep count of how many movies are in every genre\n",
        "genre_count = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
        "\n",
        "with open('drive/MyDrive/movie_labels.csv', 'r', encoding = \"ISO-8859-1\") as f:\n",
        "    reader = csv.DictReader(f, fieldnames=row_names, delimiter=',')\n",
        "    for row in reader:\n",
        "      movie_id = int(row['movie_id'])\n",
        "        \n",
        "      my_table = row['genre_array'].maketrans('','','[ ]')\n",
        "      genre_string_array = list(row['genre_array'].translate(my_table).split(','))  \n",
        "      genre_array = [int(s) for s in genre_string_array]\n",
        "\n",
        "      # Make movie_labels list\n",
        "      movie_labels[movie_id] = {}\n",
        "\n",
        "      # Add the count to the existing array\n",
        "      genre_count += genre_array\n",
        "\n",
        "      for genre in genre_dict.keys():\n",
        "        # if movie_id < 3564:\n",
        "        if genre_array[genre_dict[genre]] == 1:\n",
        "          c = count.get(genre, 0)\n",
        "          count[genre] = c + 1\n",
        "          \n",
        "          all_movies[genre] = updateDict(all_movies, genre, movie_id)\n",
        "          movies[genre] = updateDict(movies, genre, movie_id)\n",
        "\n",
        "          # Make movie_labels list\n",
        "          movie_labels[movie_id][genre] = 1\n",
        "\n",
        "        else:\n",
        "          all_movies[genre] = updateDict(all_movies, genre, movie_id)\n",
        "          non_movies[genre] = updateDict(non_movies, genre, movie_id)\n",
        "\n",
        "          # Make movie_labels list\n",
        "          movie_labels[movie_id][genre] = 0\n",
        "\n",
        "print(genre_count)\n",
        "print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fH0YD6E_Vt7X"
      },
      "source": [
        "# Creating my own way to use and load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le3NviOYZoGM"
      },
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "  'Characterizes a dataset for PyTorch'\n",
        "  def __init__(self, list_IDs, labels, YOUR_TRANSFORM):\n",
        "    'Initialization'\n",
        "    self.labels = labels\n",
        "    self.list_IDs = list_IDs\n",
        "    self.YOUR_TRANSFORM = YOUR_TRANSFORM\n",
        "\n",
        "  def __len__(self):\n",
        "    'Denotes the total number of samples'\n",
        "    return len(self.list_IDs)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      'Generates one sample of data'\n",
        "      # Select sample\n",
        "      ID = self.list_IDs[index]\n",
        "\n",
        "      # Load data and get label\n",
        "      X = self.YOUR_TRANSFORM(Image.open('movies_data_split/' + str(ID) + '.jpg').convert('RGB')) # here X should be a torch.Tensor\n",
        "      y = self.labels[ID][0] # it should also be a torch tensor torch.LongTensor(self.labels[ID] )\n",
        "\n",
        "      return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8F613u7XHjN"
      },
      "source": [
        "# Normalization\n",
        "data_transforms = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "  \n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RIKstkX5qPt"
      },
      "source": [
        "def use_model(model, genre):\n",
        "  model.eval()   # Set model to evaluate mode\n",
        "\n",
        "  # For Mystery, Romance, and War we trained without GPU, so also have to do device = cpu.\n",
        "  # device = torch.device('cpu')\n",
        "  \n",
        "  # Iterate over data.\n",
        "  predictions = []\n",
        "  for inputs, labels in movie_dataloaders[genre]:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model(inputs)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    predictions.append(preds)\n",
        "\n",
        "  final_results = torch.cat(predictions).tolist()\n",
        "\n",
        "  return final_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-4OIxj0XHjV"
      },
      "source": [
        "# Load the trained models\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wqdz7H_h5FUS"
      },
      "source": [
        "trained_models = {}\n",
        "new_trained_models = {}\n",
        "for genre in genre_dict.keys(): \n",
        "  # trained_models[genre] = torch.load('drive/MyDrive/models/{}_model'.format(genre))\n",
        "  # new_trained_models[genre] = torch.load('drive/MyDrive/models/new_{}_model'.format(genre))\n",
        "  # Use these instead if you are working without GPU:\n",
        "  trained_models[genre] = torch.load('drive/MyDrive/models/{}_model'.format(genre), map_location=torch.device('cpu'))\n",
        "  new_trained_models[genre] = torch.load('drive/MyDrive/models/new_{}_model'.format(genre), map_location=torch.device('cpu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtdAj85Helbr"
      },
      "source": [
        "# Set-based classification:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Tww8cXcJaBc"
      },
      "source": [
        "\n",
        "## Get the true labels of all movies in 'user_labels' per profile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txQp1LvKQ3Wx"
      },
      "source": [
        "row_names = ['user_id', 'movies']\n",
        "user_genre_count = {}\n",
        "user_profiles = {}\n",
        "user_labels = {}\n",
        "\n",
        "count_amount_movies = {}\n",
        "missers = []\n",
        "\n",
        "movie_dict = {}\n",
        "\n",
        "with open('drive/MyDrive/user_profiles.csv', 'r', encoding = \"ISO-8859-1\") as f:\n",
        "    reader = csv.DictReader(f, fieldnames=row_names, delimiter=',')\n",
        "    for row in reader:\n",
        "      user = row['user_id']\n",
        "\n",
        "      my_table = row['movies'].maketrans('','','[ ]')\n",
        "      movie_string_array = list(row['movies'].translate(my_table).split(','))  \n",
        "      movies = [int(s) for s in movie_string_array]\n",
        "      movie_dict[user] = movies\n",
        "      \n",
        "      user_labels[user] = {'Action':{}, 'Adventure':{}, 'Animation_Children\\'s':{}, 'Comedy':{}, 'Crime':{}, \n",
        "              'Documentary':{}, 'Drama':{}, 'Fantasy_Sci-Fi':{}, 'Film-Noir':{}, 'Horror_Thriller':{}, \n",
        "              'Musical':{}, 'Mystery':{}, 'Romance':{}, 'War':{}, 'Western':{}}\n",
        "      \n",
        "      # For every movie in this user, add the true label per genre.\n",
        "      for movie in movies:\n",
        "        if movie in movie_labels.keys():\n",
        "          for genre in genre_dict.keys():\n",
        "            label = torch.LongTensor([movie_labels[movie][genre]])\n",
        "            user_labels[user][genre][movie] = label\n",
        "            count_amount_movies[user] = count_amount_movies.get(user, 0) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37x1ipprxpET"
      },
      "source": [
        "## Get all movies into DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWIZivRhxov_"
      },
      "source": [
        "row_names = ['movie_id', 'labels']\n",
        "\n",
        "movie_dataset_sizes = {}\n",
        "movie_dataloaders = {}\n",
        "\n",
        "for genre in genre_dict.keys():\n",
        "  labels = {}\n",
        "  for movie in movie_labels.keys():\n",
        "    label = movie_labels[movie][genre]\n",
        "    labels[movie] = torch.LongTensor([label])\n",
        "  movie_dataset = Dataset(all_movies[genre], labels, data_transforms)\n",
        "  movie_generator = torch.utils.data.DataLoader(movie_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
        "\n",
        "  movie_dataset_sizes[genre] = len(all_movies[genre])\n",
        "  movie_dataloaders[genre] = movie_generator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5i12ixN9l7H"
      },
      "source": [
        "## Get the predictions for every movie"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWEoHSuzL4fy"
      },
      "source": [
        "### The following 3 blocks are used for the classification and writing it to a csv file. They are only necessary in the beginning (or to reset the predictions)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqZLX5I6LzcR"
      },
      "source": [
        "results = {}\n",
        "for genre in genre_dict.keys():\n",
        "# Run these one by one, so once for the trained_models and once for new_trained_models\n",
        "  results[genre] = use_model(trained_models[genre], genre)\n",
        "  # results[genre] = use_model(new_trained_models[genre], genre)\n",
        "  print(genre)\n",
        "  print(results[genre])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoQOdQi8BdKA"
      },
      "source": [
        "movie_dictionary = {}\n",
        "\n",
        "# Could be any genre, as length is the same for all of them.\n",
        "for i in range(len(all_movies['Action'])):\n",
        "  labels_per_movie = []\n",
        "  for genre in genre_dict.keys():\n",
        "    labels_per_movie.append(results[genre][i])\n",
        "  \n",
        "  movie_dictionary[all_movies[genre][i]] = labels_per_movie\n",
        "\n",
        "print(movie_dictionary)\n",
        "print(len(movie_dictionary))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-IvAgnbdsOf"
      },
      "source": [
        "# This one is the movie_dictionary, for the new_trained_models\n",
        "for movie in movie_dictionary.keys():\n",
        "  with open('movie_dictionary.csv', 'a', newline='') as out_csv:\n",
        "                    writer = csv.writer(out_csv, delimiter=',')\n",
        "                    writer.writerow([movie, movie_dictionary[movie]])\n",
        "\n",
        "# # This one is the new_movie_dictionary, for the new_trained_models\n",
        "# for movie in movie_dictionary.keys():\n",
        "#   with open('new_movie_dictionary.csv', 'a', newline='') as out_csv:\n",
        "#                     writer = csv.writer(out_csv, delimiter=',')\n",
        "#                     writer.writerow([movie, movie_dictionary[movie]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUc8ViYcOZ4N"
      },
      "source": [
        "### The following blocks are to load the predictions from the 'movie_dictionary.csv' file. This can be used if you already have predictions in the file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mvm_Zzde7xg0"
      },
      "source": [
        "rownames = ['movie_id', 'labels']\n",
        "old_movie_dictionary = {}\n",
        "\n",
        "with open('drive/MyDrive/movie_dictionary.csv', 'r', encoding = \"ISO-8859-1\") as f:\n",
        "    reader = csv.DictReader(f, fieldnames=row_names, delimiter=',')\n",
        "    for row in reader:\n",
        "        movie_id = int(row['movie_id'])\n",
        "        \n",
        "        my_table = row['labels'].maketrans('','','[ ]')\n",
        "        label_string_array = list(row['labels'].translate(my_table).split(','))  \n",
        "        labels = [int(s) for s in label_string_array]\n",
        "        \n",
        "        old_movie_dictionary[movie_id] = labels\n",
        "\n",
        "print(old_movie_dictionary)\n",
        "print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-ySq8ElhYhq"
      },
      "source": [
        "rownames = ['movie_id', 'labels']\n",
        "new_movie_dictionary = {}\n",
        "\n",
        "with open('drive/MyDrive/new_movie_dictionary.csv', 'r', encoding = \"ISO-8859-1\") as f:\n",
        "    reader = csv.DictReader(f, fieldnames=row_names, delimiter=',')\n",
        "    for row in reader:\n",
        "        movie_id = int(row['movie_id'])\n",
        "        \n",
        "        my_table = row['labels'].maketrans('','','[ ]')\n",
        "        label_string_array = list(row['labels'].translate(my_table).split(','))  \n",
        "        labels = [int(s) for s in label_string_array]\n",
        "        \n",
        "        new_movie_dictionary[movie_id] = labels\n",
        "\n",
        "print(new_movie_dictionary)\n",
        "print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_reWRbnnKehl"
      },
      "source": [
        "# Testing and accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5tC_VY5NJBx"
      },
      "source": [
        "## Make the test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-IwG9XaK595"
      },
      "source": [
        "true_labels = {}\n",
        "\n",
        "for user in user_labels.keys():\n",
        "  true_labels[user] = {}\n",
        "  for genre in genre_dict.keys():\n",
        "    movies = list(user_labels[user][genre].keys())\n",
        "    count = 0\n",
        "    for movie in movies:\n",
        "      count += user_labels[user][genre][movie]\n",
        "\n",
        "    fraction = count/len(movies)\n",
        "    if fraction >= 0.25:\n",
        "      true_labels[user][genre] = 1\n",
        "    else:\n",
        "      true_labels[user][genre] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y41-7kH7KhMZ"
      },
      "source": [
        "# Get the count to make train, val, test splits.\n",
        "count = {}\n",
        "users = {}\n",
        "non_users = {}\n",
        "\n",
        "for genre in genre_dict.keys():\n",
        "  count[genre] = 0\n",
        "  users[genre] = []\n",
        "  non_users[genre] = []\n",
        "\n",
        "  for u in true_labels.keys():\n",
        "    if true_labels[u][genre] == 1:\n",
        "      users[genre].append(u)\n",
        "      count[genre] +=1\n",
        "    else:\n",
        "      non_users[genre].append(u)\n",
        "  \n",
        "  # The count should be the amount of the smallest side (1's or 0's)\n",
        "  # to be able to get an equal amount of 1's and 0's in every split.\n",
        "  if count[genre] > len(true_labels)/2:\n",
        "    count[genre] = len(true_labels) - count[genre]\n",
        "  print(genre, count[genre])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAEKs4hLKhFX"
      },
      "source": [
        "train_N = {}\n",
        "val_N   = {}\n",
        "test_N  = {}\n",
        "\n",
        "# train_split = {}\n",
        "# val_split   = {}\n",
        "test_split  = {}\n",
        "\n",
        "for genre in genre_dict.keys():\n",
        "  val_N[genre] = math.floor(count[genre]*0.1)\n",
        "  test_N[genre] = math.floor(count[genre]*0.1)\n",
        "  train_N[genre] = count[genre] - val_N[genre] - test_N[genre]\n",
        "\n",
        "  if val_N[genre] == 0: # There are not a lot of profiles with documentary as 1.\n",
        "    val_N[genre] = 1\n",
        "    test_N[genre] = 1\n",
        "    train_N[genre] = count[genre] - 2\n",
        "\n",
        "  # train_split[genre] = users[genre][:train_N[genre]] + non_users[genre][:train_N[genre]]\n",
        "  # val_split[genre]   = users[genre][train_N[genre]:train_N[genre]+val_N[genre]] + non_users[genre][train_N[genre]:train_N[genre]+val_N[genre]]\n",
        "  test_split[genre]  = users[genre][train_N[genre]+val_N[genre]:] + non_users[genre][train_N[genre]+val_N[genre]:train_N[genre]+val_N[genre]+test_N[genre]]\n",
        "\n",
        "print(train_N)\n",
        "print(val_N)\n",
        "print(test_N)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFcDlfkCSZtR"
      },
      "source": [
        "## Get the true labels for the users in the test split."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqHKDj6WON8c"
      },
      "source": [
        "profile_true_labels = {}\n",
        "\n",
        "for genre in genre_dict.keys():\n",
        "  profile_true_labels[genre] = {}\n",
        "\n",
        "  for user in test_split[genre]:\n",
        "    movies = list(user_labels[user][genre].keys())\n",
        "    count = 0\n",
        "    for movie in movies:\n",
        "      count += user_labels[user][genre][movie]\n",
        "      \n",
        "    fraction = count/len(movies)\n",
        "    if fraction >= 0.25:\n",
        "      profile_true_labels[genre][user] = 1\n",
        "    else:\n",
        "      profile_true_labels[genre][user] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8j0LnC1RSRc-"
      },
      "source": [
        "print(profile_true_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EujSggWs6NLW"
      },
      "source": [
        "## Get the predicted labels for the users"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWZCAl_BYS71"
      },
      "source": [
        "old_profile_predicted_labels = {}\n",
        "new_profile_predicted_labels = {}\n",
        "\n",
        "for genre in genre_dict.keys():\n",
        "  old_profile_predicted_labels[genre] = {}\n",
        "  new_profile_predicted_labels[genre] = {}\n",
        "\n",
        "  for user in test_split[genre]:\n",
        "    movies = list(user_labels[user][genre].keys())\n",
        "    old_count = 0\n",
        "    new_count = 0\n",
        "\n",
        "    for movie in movies:\n",
        "      old_count += old_movie_dictionary[movie][genre_dict[genre]]\n",
        "      new_count += new_movie_dictionary[movie][genre_dict[genre]]\n",
        "\n",
        "    old_fraction = old_count/len(movies)\n",
        "    if old_fraction >= 0.25:\n",
        "      old_profile_predicted_labels[genre][user] = 1\n",
        "    else:\n",
        "      old_profile_predicted_labels[genre][user] = 0\n",
        "\n",
        "    new_fraction = new_count/len(movies)\n",
        "    if new_fraction >= 0.25:\n",
        "      new_profile_predicted_labels[genre][user] = 1\n",
        "    else:\n",
        "      new_profile_predicted_labels[genre][user] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCaGKiUYYS8A"
      },
      "source": [
        "print(old_profile_predicted_labels)\n",
        "print(new_profile_predicted_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aptF7RnZYKdC"
      },
      "source": [
        "# Get the accuracy for the genres (profiles)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7lWYI5_ORJy"
      },
      "source": [
        "old_profiles_acc = []\n",
        "new_profiles_acc = []\n",
        "\n",
        "for genre in genre_dict.keys():\n",
        "  old_count = 0\n",
        "  new_count = 0\n",
        "\n",
        "  for user in test_split[genre]:\n",
        "    old_pred = old_profile_predicted_labels[genre][user]\n",
        "    new_pred = new_profile_predicted_labels[genre][user]\n",
        "    \n",
        "    true = profile_true_labels[genre][user]\n",
        "    old_count += (old_pred == true)\n",
        "    new_count += (new_pred == true)\n",
        "\n",
        "  old_accuracy = old_count / len(old_profile_predicted_labels[genre]) \n",
        "  old_profiles_acc.append(old_accuracy)\n",
        "  \n",
        "  new_accuracy = new_count / len(new_profile_predicted_labels[genre])  \n",
        "  new_profiles_acc.append(new_accuracy)\n",
        "  \n",
        "\n",
        "print('Done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoS6YPcY6gf2"
      },
      "source": [
        "# Visualise the similarity for resulting F1 scores and the amount of movies per genre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lU2b1EmoKddR"
      },
      "source": [
        "print(old_profiles_acc)\n",
        "print(new_profiles_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n2NInG4S1_S"
      },
      "source": [
        "# Visualise the distribution of genres over the movies\n",
        "genres = ['Action', 'Adventure', 'Anim/Child', 'Comedy', 'Crime', \n",
        "          'Documentary', 'Drama', 'Fant/SF', 'Film-Noir', 'Hor/Thri', \n",
        "          'Musical', 'Mystery', 'Romance', 'War', 'Western']\n",
        "\n",
        "x = np.arange(len(genres))\n",
        "width = 0.3\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(16,8))\n",
        "\n",
        "# Normalize genre_count to plot them together with F1 scores.\n",
        "genre_count_normalized = [g/len(movie_labels) for g in genre_count]\n",
        "\n",
        "rects1 = ax.bar(x - width, genre_count_normalized, width, label = 'Percentage of movies per genre')\n",
        "rects2 = ax.bar(x, old_profiles_acc, width, label = 'Accuracy of set-based classifier with single-image validation')\n",
        "rects3 = ax.bar(x + width, new_profiles_acc, width, label = 'Accuracy of set-based classifier with profile validation')\n",
        "\n",
        "ax.set_ylabel('Accuracy, percentages')\n",
        "ax.set_title('Accuracy on test set of profiles and percentage of movie count per genre')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(genres)\n",
        "ax.legend()\n",
        "\n",
        "plt.xlabel('Genres')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}